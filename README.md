# ğŸŒ± SPROUT  
**Smart Processing for Resume, Opportunities, and Unique Talent**

SPROUT is an AI-powered system designed to streamline the recruitment process by transforming unstructured CVs into structured, machine-readable data.  
The project is built around four main features:  

1. CV Parsing & Normalization  
2. Specialized Skill Analysis  
3. Market Intelligence (newly added)  
4. Recommendation & Report Generation (to be implemented)  

This repository currently implements:  
- **CV Parsing & Normalization Agent** (Point 1)  
- **Specialized Skill Analyst Agent** (Point 2)  
- **Market Intelligence Agent** (Point 3)  

---

## ğŸš€ Feature: CV Parsing & Normalization
The **CV Parser Agent** plays the role of a data engineer.  
Its task is to:  

- Input: Ingest a raw CV (PDF, DOCX, or TXT).  
- Process: Extract key information using an AI agent.  
- Output: Structured JSON that can be consumed by downstream systems.  

---

## ğŸš€ Feature: Specialized Skill Analyst
The **Skill Analyst Agent** plays the role of a subject matter expert.  
Its task is to:  

- Input: Structured JSON data from the CV Parser Agent.  
- Process: Analyze explicit skills, infer implicit skills from projects/experience, and identify transferable skills.  
- Output: Enhanced structured JSON with skill categorization and reasoning.  

---

## ğŸš€ Feature: Market Intelligence
The **Market Intelligence Agent** plays the role of a market researcher.  
Its task is to:  

- Input: The target role (e.g., "Senior AI Engineer").  
- Process: Use Tavily Search API to query job requirements and industry trends. Summarize in-demand skills and technologies.  
- Output: JSON object containing role, in-demand skills, and a concise market summary.  

### Example Output
```json
{
  "role": "Senior AI Engineer",
  "in_demand_skills": ["Python", "PyTorch", "TensorFlow", "MLOps", "AWS"],
  "summary": "Senior AI Engineers are expected to have strong Python skills, expertise in PyTorch/TensorFlow, experience with cloud platforms, and knowledge of MLOps best practices."
}
```
---

## âš™ï¸ Tech Stack
- FastAPI â†’ REST API framework  
- Pydantic â†’ Response schema validation & normalization  
- LangChain + OpenAI â†’ AI agent for text parsing and reasoning  
- Tavily API â†’ External search tool for market intelligence  
- PyPDF2 / python-docx â†’ Text extraction utilities  
- pytest + httpx â†’ Unit testing framework  

---

## ğŸ“‚ Project Structure (simplified)
```json
sprout/
â”‚â”€â”€ app/  
â”‚   â”œâ”€â”€ src/  
â”‚   â”‚   â”œâ”€â”€ agents/  
â”‚   â”‚   â”‚   â”œâ”€â”€ cv_parser.py        # AI CV Parser Agent  
â”‚   â”‚   â”‚   â”œâ”€â”€ skill_analyst.py    # AI Skill Analyst Agent  
â”‚   â”‚   â”‚   â””â”€â”€ market_intel.py     # Market Intelligence Agent  
â”‚   â”‚   â”œâ”€â”€ utils/  
â”‚   â”‚   â”‚   â””â”€â”€ extractor.py        # Extractor for PDF/DOCX/TXT  
â”‚   â”‚   â””â”€â”€ schemas/  
â”‚   â”‚       â”œâ”€â”€ cv_parser.py        # Schema for CV response  
â”‚   â”‚       â”œâ”€â”€ skill_analysis.py   # Schema for Skill Analyst response  
â”‚   â”‚       â””â”€â”€ market_intel.py     # Schema for Market Intelligence response  
â”‚   â”œâ”€â”€ main.py                     # FastAPI entry point  
â”‚â”€â”€ tests/  
â”‚   â”œâ”€â”€ data/                       # Test CVs (pdf, docx, txt)  
â”‚   â”œâ”€â”€ test_cv_parser.py           # Unit tests for CV parser  
â”‚   â”œâ”€â”€ test_skill_analyst.py       # Unit tests for skill analyst  
â”‚   â””â”€â”€ test_market_intel.py        # Unit tests for market intelligence  
```
---

## â–¶ï¸ Running the Application
1. Install dependencies:
   poetry install

2. Set your API keys:
   export OPENAI_API_KEY=your_openai_key
   export TAVILY_API_KEY=your_tavily_key

3. Start the FastAPI server:
   uvicorn app.main:app --reload

4. Open Swagger UI for testing:
   http://127.0.0.1:8000/docs

Endpoints available:
- POST `/api/agent/cv-parser` â†’ upload CV file and get structured JSON  
- POST `/api/agent/skill-analyst` â†’ analyze structured CV JSON for skills  
- POST `/api/agent/market-intelligent` â†’ query market demands for a given role  

---

## ğŸ“ How to Get Tavily API Key
1. Go to https://tavily.com  
2. Sign up for a free account  
3. Navigate to **API Keys** in your dashboard  
4. Copy your key and add it to your environment:
   export TAVILY_API_KEY=your_tavily_key

---

## ğŸ¤” Why Tavily API?
- **LangChain Native Integration** â†’ Tavily has first-class support in LangChain, so itâ€™s plug-and-play.  
- **Relevant Results** â†’ Tavily is optimized for AI agent search, unlike generic search engines.  
- **AI-Oriented** â†’ Results are structured (title, url, snippet), making them easier for LLMs to consume.  
- **Fallback Ready** â†’ If quota runs out, itâ€™s easy to replace with DuckDuckGo search as backup.  

This makes Tavily the most practical and professional choice for building the Market Intelligence Agent.  

---

## âœ… Testing
Unit tests are included for all agents.  

Run tests:
   pytest -v

Tests cover:
- CV Parser â†’ parses PDF/DOCX/TXT into JSON  
- Skill Analyst â†’ analyzes explicit/implicit/transferable skills  
- Market Intelligence â†’ queries (mocked) Tavily results and validates JSON output  